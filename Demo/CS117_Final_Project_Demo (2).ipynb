{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-nExVGWwZrM",
        "outputId": "f3225f1e-72b2-4eba-d701-326be1784ab2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'nvidia-smi' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# prompt: check GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "FyZKAeaxx-jP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from detect import run\n",
        "from models.common import DetectMultiBackend\n",
        "from models.classification import Classification_model\n",
        "from utils.torch_utils import select_device\n",
        "ROOT = os.getcwd() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZMlbRlyurYT"
      },
      "source": [
        "# Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYUBHUHuxVUW"
      },
      "source": [
        "## Input:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "jue-nlv4wefm"
      },
      "outputs": [],
      "source": [
        "ROOT = os.getcwd() \n",
        "file_output_dir = os.path.join(ROOT, 'Demo', 'annotation.txt') \n",
        "video_output_dir = os.path.join(ROOT, 'Demo', 'video_output.mp4')\n",
        "video_dir = r'E:\\App\\Git\\repos\\yolov9-face-detection\\yolov9\\WIN_20240610_18_31_30_Pro.mp4'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cptHoRm1x2OG"
      },
      "source": [
        "## Tách từng frame và xử lí"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ixTwE26T39NA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fusing layers... \n",
            "yolov9-c summary: 604 layers, 50698278 parameters, 0 gradients, 236.6 GFLOPs\n"
          ]
        }
      ],
      "source": [
        "class Params:\n",
        "    def __init__(self):\n",
        "        self.detection_weights = os.path.join(ROOT, 'detection_weights.pt')\n",
        "        self.classification_weights = os.path.join(ROOT, 'classification_weights.pt')\n",
        "        self.processing_dir = os.path.join(ROOT, 'Demo')\n",
        "        self.detection_name = 'exp'\n",
        "        self.boxes_dir = os.path.join(self.processing_dir, self.detection_name, 'labels', 'frame.txt') \n",
        "        self.data = os.path.join(ROOT, 'data', 'coco.yaml')\n",
        "\n",
        "\n",
        "        self.detection_model = DetectMultiBackend(self.detection_weights, device=device, dnn=False, data=self.data, fp16=False)\n",
        "        self.classification_model = Classification_model(self.classification_weights, num_classes=7)\n",
        "\n",
        "params = Params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "fkOr_hqIKiGy"
      },
      "outputs": [],
      "source": [
        "def delete_file(folder_path):\n",
        "    # Kiểm tra nếu đường dẫn là một tệp\n",
        "    if os.path.isfile(folder_path):\n",
        "        os.remove(folder_path)\n",
        "\n",
        "    # Kiểm tra nếu đường dẫn là một thư mục\n",
        "    elif os.path.isdir(folder_path):\n",
        "        for file_name in os.listdir(folder_path):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            delete_file(file_path)\n",
        "        os.rmdir(folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "OfuKWfm50yCi"
      },
      "outputs": [],
      "source": [
        "def detection(source, frame):\n",
        "      #command = f'python {params.detection} --weights {params.weights} --source {source} --project {params.processing_dir} --name {params.detection_name} --save-txt --nosave'\n",
        "      run(model = params.detection_model, weights= params.detection_weights, source=source, project=params.processing_dir, name = params.detection_name, save_txt = True, nosave= True)\n",
        "      boxes_dir = params.boxes_dir\n",
        "\n",
        "      # đọc file boundingbox vừa được tạo ra\n",
        "      with open(boxes_dir, 'r') as file:\n",
        "          lines = file.readlines()\n",
        "\n",
        "      # Tách từng dòng và xử lý từng hàng\n",
        "      processed_lines = []\n",
        "      for line in lines:\n",
        "          # Tách các giá trị trong dòng, bỏ qua các khoảng trắng không cần thiết\n",
        "          values = line.strip().split()\n",
        "          # Chuyển các giá trị từ chuỗi sang kiểu float (nếu cần)\n",
        "          float_values = [float(value) for value in values]\n",
        "          x, y, w, h = float_values[1:5]\n",
        "          x, y, w, h = map(int, [x * frame.shape[1], y * frame.shape[0],\n",
        "                      w * frame.shape[1], h * frame.shape[0]])\n",
        "          processed_lines.append([x, y, w, h])\n",
        "      delete_file(params.processing_dir + '/' + params.detection_name)\n",
        "      return processed_lines\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "JRBpoXQeGISv"
      },
      "outputs": [],
      "source": [
        "def draw_bounding_boxes(frame, bounding_boxes, labels):\n",
        "    # Vẽ bounding boxes trên frame\n",
        "    for bbox,label in zip(bounding_boxes, labels):\n",
        "        x, y, w, h = bbox\n",
        "        x1, y1 = x - w // 2, y - h // 2\n",
        "        x2, y2 = x1 + w, y1 + h\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f'{label}', (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
        "    return frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "n4qUDNNrG2Nl"
      },
      "outputs": [],
      "source": [
        "def cut_image(frame, bounding_boxes, gain = 1.02, pad = 10):\n",
        "    face_images = []\n",
        "    for bbox in bounding_boxes:\n",
        "        x, y, w, h = bbox\n",
        "        x1, y1 = x - w // 2, y - h // 2\n",
        "        x2, y2 = x1 + w, y1 + h\n",
        "        crop = frame[y1:y2, x1:x2]\n",
        "        crop = cv2.resize(crop, (100, 100))\n",
        "        face_images.append(crop)\n",
        "    return face_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "GvJh_nnoHYfc"
      },
      "outputs": [],
      "source": [
        "def classification(model, face_images):\n",
        "    class_labels = np.array(['Surprise', 'Fear', 'Disgust', 'Happy', 'Sad', 'Angry', 'Neutral'])\n",
        "    x_tensor = torch.tensor(face_images, dtype=torch.float32).permute(0, 3, 1, 2).to(select_device(''))\n",
        "    output = model(x_tensor)\n",
        "    probabilities = torch.nn.functional.softmax(output, dim=1)\n",
        "    predicted_classes = torch.argmax(probabilities, dim=1)\n",
        "\n",
        "    label_sto = []\n",
        "    for i in range(len(predicted_classes)):\n",
        "        label_sto.append(class_labels[predicted_classes[i].item()])\n",
        "    return label_sto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "u6yrRZ4PuF2A"
      },
      "outputs": [],
      "source": [
        "def write_to_annotation_file(file_path, bounding_boxes, labels, frame_idx):\n",
        "    with open(file_path, 'a') as file:\n",
        "        for bbox, label in zip(bounding_boxes, labels):\n",
        "            x, y, w, h = bbox\n",
        "            file.write(f\"{frame_idx} {x} {y} {w} {h} {label}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h184oyBaEOgk",
        "outputId": "b318fc23-1f91-41a6-bb82-4d5505e1f39a"
      },
      "outputs": [],
      "source": [
        "def create_video_output(video, video_output_dir): \n",
        "    fps = video.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Khởi tạo đối tượng VideoWriter để tạo video\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Xác định codec\n",
        "    return cv2.VideoWriter(video_output_dir, fourcc, fps, (width, height)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main(video_dir, file_output_dir:str = os.path.join(ROOT, 'Demo', 'annotation.txt'), video_output_dir: str = os.path.join(ROOT, 'Demo', 'video_output.mp4')):\n",
        "    \n",
        "    # Đọc và lấy số frame của video hiện tại\n",
        "    video = cv2.VideoCapture(video_dir)\n",
        "    num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    out = create_video_output(video, video_output_dir)\n",
        "        \n",
        "    for frame_idx in range(num_frames):\n",
        "        if (frame_idx % 10 == 0):\n",
        "            print(f\"Processing frame {frame_idx} of {num_frames}\")\n",
        "        # Đọc frame\n",
        "        ret, frame = video.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame_path = os.path.join(params.processing_dir, 'frame' + '.jpg')\n",
        "        cv2.imwrite(frame_path, frame)\n",
        "\n",
        "        # Chạy detection\n",
        "        bounding_boxes = detection(frame_path, frame)\n",
        "\n",
        "        #Cắt cận ảnh khuôn mặt và resize\n",
        "        face_images = cut_image(frame, bounding_boxes)\n",
        "\n",
        "        #Phân loại cảm xúc\n",
        "        labels = classification(params.classification_model, face_images)\n",
        "\n",
        "        #Ghi lại thông tin vào file annotation.txt\n",
        "        write_to_annotation_file(file_output_dir, bounding_boxes, labels, frame_idx)\n",
        "\n",
        "        #Vex bounding boxes và labels cho frame hiện tại\n",
        "        drawn_frame = draw_bounding_boxes(frame, bounding_boxes, labels)\n",
        "\n",
        "        #Thêm frame đã được vẽ bounding boxes và labels vào video output\n",
        "        out.write(frame)\n",
        "        \n",
        "        # Frame sau khi xử lí xong\n",
        "        os.remove(frame_path)\n",
        "\n",
        "    # Đóng video\n",
        "    video.release()\n",
        "    out.release()\n",
        "\n",
        "    print(f\"Bounding boxes and labels saved to {file_output_dir}\")\n",
        "    print(f\"Results video saved to {video_output_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing frame 0 of 65\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing frame 10 of 65\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing frame 20 of 65\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing frame 30 of 65\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing frame 40 of 65\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing frame 50 of 65\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing frame 60 of 65\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n",
            "YOLOv5  2024-6-11 Python-3.12.2 torch-2.3.0+cpu CPU\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bounding boxes and labels saved to e:\\App\\Git\\repos\\yolov9-face-detection-Copy\\yolov9\\Demo\\annotation.txt\n",
            "Results video saved to e:\\App\\Git\\repos\\yolov9-face-detection-Copy\\yolov9\\Demo\\video_output.mp4\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    video_dir = r'E:\\App\\Git\\repos\\yolov9-face-detection-Copy\\yolov9\\WIN_20240612_10_54_30_Pro.mp4'\n",
        "    main(video_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
